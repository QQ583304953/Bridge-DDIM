{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b076bd1a-b236-4fbc-953d-8295b25122ae",
   "metadata": {},
   "source": [
    "# 🔥 Diffusion Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235cbd1-f136-411c-88d9-f69f270c0b96",
   "metadata": {},
   "source": [
    "In this notebook, we'll walk through the steps required to train your own diffusion model on the Oxford flowers dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bacc8be-c1d2-4108-aa7c-7453dbc777a6",
   "metadata": {},
   "source": [
    "The code is adapted from the excellent ['Denoising Diffusion Implicit Models' tutorial](https://keras.io/examples/generative/ddim/) created by András Béres available on the Keras website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84acc7be-6764-4668-b2bb-178f63deeed3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseaborn-v0_8-colorblind\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     layers,\n\u001b[0;32m     13\u001b[0m     models,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     activations,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnotebooks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display, sample_batch\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\__init__.py:42\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:96\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:419\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompress\u001b[39m(element):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwrapt\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py:36\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"## Functions for working with arbitrarily nested sequences of elements.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03mNOTE(mrry): This fork of the `tensorflow.python.util.nest` module\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m   arrays.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m _sparse_tensor\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_util\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m type_spec\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_sparse_ops\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m internal\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\ops\\gen_sparse_ops.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m op_def_registry \u001b[38;5;28;01mas\u001b[39;00m _op_def_registry\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops \u001b[38;5;28;01mas\u001b[39;00m _ops\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m op_def_library \u001b[38;5;28;01mas\u001b[39;00m _op_def_library\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated_endpoints\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch \u001b[38;5;28;01mas\u001b[39;00m _dispatch\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text_format\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flags\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_pb2\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\core\\config\\flags.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# pylint: disable=invalid-import-order, g-bad-import-order, unused-import\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flags_pybind\n\u001b[0;32m     22\u001b[0m FLAGS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfig\u001b[39m():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-colorblind\")\n",
    "\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import (\n",
    "    layers,\n",
    "    models,\n",
    "    optimizers,\n",
    "    utils,\n",
    "    callbacks,\n",
    "    metrics,\n",
    "    losses,\n",
    "    activations,\n",
    ")\n",
    "\n",
    "from notebooks.utils import display, sample_batch\n",
    "\n",
    "import time\n",
    "startTime=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5",
   "metadata": {},
   "source": [
    "## 0. Parameters <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ee6ce-129f-4833-b0c5-fa567381c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#调整参数\n",
    "BATCH_SIZE = 64 #查看显存占用比例“nvidia-smi”。\n",
    "DATASET_REPETITIONS = 5 #数据集的重复次数。\n",
    "LOAD_MODEL = False\n",
    "\n",
    "NOISE_EMBEDDING_SIZE = 32 #正弦嵌入层将一个标量数值 (噪声方差) 转换到一个向量，32即向量维数\n",
    "PLOT_DIFFUSION_STEPS = 20 #生成图像时，去除噪音的步骤数目\n",
    "\n",
    "EMA = 0.999 #指数移动平均参数\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "EPOCHS = 150 # 4m/轮/(48, 192)\n",
    "\n",
    "#固定参数\n",
    "train_dir=\".\\\\png 192x48_GRAY\\\\\" #文件名字符数目不能过多，否则出错，故在旋转、缩放、平移变换时减少文件名字符。\n",
    "IMAGE_SIZE =  (48, 192) #再小清晰度就不满足了\n",
    "CHANNELS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f5e63-e36a-4dc8-9f03-cb29c1fa5290",
   "metadata": {},
   "source": [
    "## 1. Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089c317-2d66-4631-81f8-1a8230635845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = utils.image_dataset_from_directory(\n",
    "    train_dir,  \n",
    "    labels=None,\n",
    "    color_mode=\"grayscale\", #默认RGB三通道\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=None,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    interpolation=\"bilinear\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20697102-8c8d-4582-88d4-f8e2af84e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "def preprocess(img):\n",
    "    img = tf.cast(img, \"float32\") / 255.0 #tf.cast()函数：数据类型转换.由0~255放缩到0~1\n",
    "    return img\n",
    "\n",
    "\n",
    "train = train_data.map(lambda x: preprocess(x))\n",
    "train = train.repeat(DATASET_REPETITIONS) #repeat(count) 用于将数据重复count次，相当于我们训练时的epoch\n",
    "train = train.batch(BATCH_SIZE, drop_remainder=True) #batch(batch_size)用于将数据划分为多个batch。     drop_remainder：True表示剩下的数据不足batch_size个 仍掉。默认值为False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1a420-699e-4869-8d10-3c049dbad030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some items of clothing from the training set\n",
    "train_sample = sample_batch(train)\n",
    "print(train_sample.shape) \n",
    "np.savetxt('train_sample[0].txt', train_sample[0][:,:,0])  #像素值0~1\n",
    "display(train_sample, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53945d9-b7c5-49d0-a356-bcf1d1e1798b",
   "metadata": {},
   "source": [
    "### 1.1 Diffusion schedules <a name=\"diffusion_schedules\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330083c0-642e-4745-b160-1938493152da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个方案最复杂\n",
    "def linear_diffusion_schedule(diffusion_times): #线性扩散计划。0~1均匀分布。\n",
    "    min_rate = 0.0001 #一开始的beta值，即一开始添加1%的噪音\n",
    "    max_rate = 0.02 #最后一步的beta值，可见添加噪音的比例越来越大\n",
    "    betas = min_rate + diffusion_times * (max_rate - min_rate) #min_rate~max_rate均匀分布。\n",
    "    alphas = 1 - betas #0.9999~0.98002均匀分布\n",
    "    alpha_bars = tf.math.cumprod(alphas) #cumprod()用于计算输入张量的累积乘积\n",
    "    signal_rates = tf.sqrt(alpha_bars) #返回张量每个元素的平方根。\n",
    "    noise_rates = tf.sqrt(1 - alpha_bars) #含有噪音的比例，由0向1演变.\n",
    "    return noise_rates, signal_rates #“线性扩散代码解释.png”\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08bb63-148f-4813-96c6-adec54d8956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个方案最简单，diffusion_times约等于noise_rates\n",
    "def cosine_diffusion_schedule(diffusion_times): \n",
    "    signal_rates = tf.cos(diffusion_times * math.pi / 2)\n",
    "    noise_rates = tf.sin(diffusion_times * math.pi / 2)\n",
    "    return noise_rates, signal_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e1557-4ea5-4cd8-8f41-66a99ee3898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#最终采用的方案，diffusion_times相当于noise_rates[但是有点偏差]\n",
    "# 我们将使用的offset cosine扩散计划，其调整计划来确保加噪steps在加噪的开始阶段不至于过小。\n",
    "def offset_cosine_diffusion_schedule(diffusion_times):\n",
    "    min_signal_rate = 0.02\n",
    "    max_signal_rate = 0.95\n",
    "    start_angle = tf.acos(max_signal_rate) #18.2度\n",
    "    end_angle = tf.acos(min_signal_rate) #88.9度\n",
    "\n",
    "    diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n",
    "\n",
    "    signal_rates = tf.cos(diffusion_angles) #在0.95~0.02之间\n",
    "    noise_rates = tf.sin(diffusion_angles) #0.312~0.9998。diffusion_times（0~1）相当于noise_rates[但是有点偏差]\n",
    "\n",
    "    return noise_rates, signal_rates\n",
    "\n",
    "diffusion_times=tf.convert_to_tensor([(1-x*1 / 20) for x in range(20)])\n",
    "print(diffusion_times)\n",
    "print(offset_cosine_diffusion_schedule(diffusion_times))\n",
    "print(offset_cosine_diffusion_schedule(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5f3c3-4797-4b58-b559-45589f59aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1000\n",
    "diffusion_times = tf.convert_to_tensor([x / T for x in range(T)]) #0~1均匀分布。\n",
    "\n",
    "linear_noise_rates, linear_signal_rates = linear_diffusion_schedule(    diffusion_times)\n",
    "cosine_noise_rates, cosine_signal_rates = cosine_diffusion_schedule(    diffusion_times)\n",
    "(    offset_cosine_noise_rates,    offset_cosine_signal_rates,) = offset_cosine_diffusion_schedule(diffusion_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b7b5a-c79c-4728-8778-10656541dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    diffusion_times, linear_signal_rates**2, linewidth=1.5, label=\"linear\"\n",
    ")\n",
    "plt.plot(\n",
    "    diffusion_times, cosine_signal_rates**2, linewidth=1.5, label=\"cosine\"\n",
    ")\n",
    "plt.plot(\n",
    "    diffusion_times,    offset_cosine_signal_rates**2,    linewidth=1.5,    label=\"offset_cosine\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"t/T\", fontsize=12)\n",
    "plt.ylabel(r\"$\\bar{\\alpha_t}$ (signal)\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eac1df-3a74-4432-9d4d-0ccfbb5dc24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    diffusion_times, linear_noise_rates**2, linewidth=1.5, label=\"linear\"\n",
    ")\n",
    "plt.plot(\n",
    "    diffusion_times, cosine_noise_rates**2, linewidth=1.5, label=\"cosine\"\n",
    ")\n",
    "plt.plot(\n",
    "    diffusion_times,\n",
    "    offset_cosine_noise_rates**2,\n",
    "    linewidth=1.5,\n",
    "    label=\"offset_cosine\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"t/T\", fontsize=12)\n",
    "plt.ylabel(r\"$1-\\bar{\\alpha_t}$ (noise)\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598d401-867d-450c-a3ba-6823bf309456",
   "metadata": {},
   "source": [
    "## 2. Build the model <a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b305c3a-75c5-4b02-9130-79b661fc63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_embedding(x):  #正弦嵌入层，将一个标量数值 (噪声方差) 转换到一个向量（对应图像通道）\n",
    "    frequencies = tf.exp(   #最终得到指数值\n",
    "        tf.linspace(          #均匀分布，返回为频率的最大放缩因子\n",
    "            tf.math.log(1.0), #从0到ln(1000)\n",
    "            tf.math.log(1000.0),\n",
    "            NOISE_EMBEDDING_SIZE // 2,  #生成的个数\n",
    "        )\n",
    "    )\n",
    "    angular_speeds = 2.0 * math.pi * frequencies\n",
    "    embeddings = tf.concat(\n",
    "        [tf.sin(angular_speeds * x), tf.cos(angular_speeds * x)], axis=3\n",
    "    )\n",
    "    return embeddings #这个函数输入是方差标量，输出结果shape是(1x1x32)，值为-1~1（sin、cos函数值域）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711f6fb-6b43-4e79-9450-faef9f2afdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = []\n",
    "for y in np.arange(0, 1, 0.01): #y为噪音方差\n",
    "    embedding_list.append(sinusoidal_embedding(np.array([[[[y]]]]))[0][0][0])\n",
    "embedding_array = np.array(np.transpose(embedding_list))  #np.transpose（）数组转置\n",
    "fig, ax = plt.subplots() #fig代表绘图窗口(Figure)；ax代表这个绘图窗口上的坐标系(axis)，一般会继续对ax进行操作。\n",
    "ax.set_xticks(\n",
    "    np.arange(0, 100, 10), labels=np.round(np.arange(0.0, 1.0, 0.1), 1)\n",
    ")\n",
    "ax.set_ylabel(\"embedding dimension\", fontsize=8) #这里有32个值\n",
    "ax.set_xlabel(\"noise variance\", fontsize=8)\n",
    "plt.pcolor(embedding_array, cmap=\"coolwarm\") #plt.pcolor()是matplotlib库中的一种2D图像绘制函数，它可以根据数据值的大小自动填充不同颜色，从而为我们展示出数据的分布情况。\n",
    "plt.colorbar(orientation=\"horizontal\", label=\"embedding value\") #添加颜色条\n",
    "#ax.imshow(embedding_array, interpolation=\"nearest\", origin=\"lower\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac9c2c-c5bc-4533-b78f-0c878a33893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualBlock(width): #width通道数\n",
    "    def apply(x): #这里两个def定义函数，这是“函数嵌套.png”\n",
    "        input_width = x.shape[3] #图像x的通道数\n",
    "        if input_width == width: #检查输入的通道数是否匹配，如不是则在跳跃连接上引入一个额外的Conv2D层\n",
    "            residual = x\n",
    "        else:\n",
    "            residual = layers.Conv2D(width, kernel_size=1)(x)\n",
    "        x = layers.BatchNormalization(center=False, scale=False)(x) #keras批标准化\n",
    "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\", activation=activations.swish)(x)\n",
    "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
    "        x = layers.Add()([x, residual]) #layers.add()相应元素数值相加，H,W,C不改变；tf.keras.layers.concatenate（）拼接，H 、 W 不改变 ， 但是通道数增加\n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "def DownBlock(width, block_depth): #width通道数\n",
    "    def apply(x): \n",
    "        x, skips = x \n",
    "        for _ in range(block_depth):\n",
    "            x = ResidualBlock(width)(x) #这里两个输入见“函数嵌套.png”\n",
    "            skips.append(x)\n",
    "        x = layers.AveragePooling2D(pool_size=2)(x) #平均池化层，pool_size 池化窗口大小，strides: 池化步长，默认值等于 pool_size\n",
    "        return x\n",
    "\n",
    "    return apply \n",
    "\n",
    "\n",
    "def UpBlock(width, block_depth):\n",
    "    def apply(x):\n",
    "        x, skips = x \n",
    "        x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x)\n",
    "        for _ in range(block_depth):\n",
    "            x = layers.Concatenate()([x, skips.pop()]) #列表pop()方法：删除并返回列表中的最后一个元素。\n",
    "            x = ResidualBlock(width)(x)\n",
    "        return x \n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8455e5d-2cc7-4d72-94e1-412a0f5e69b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the U-Net\n",
    "\n",
    "noisy_images = layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS)) #输入带有噪音的图像\n",
    "x = layers.Conv2D(32, kernel_size=1)(noisy_images)\n",
    "\n",
    "noise_variances = layers.Input(shape=(1, 1, 1)) #输入噪音方差。\n",
    "noise_embedding = layers.Lambda(sinusoidal_embedding)(noise_variances) \n",
    "noise_embedding = layers.UpSampling2D(size=IMAGE_SIZE, interpolation=\"nearest\")(noise_embedding) \n",
    "\n",
    "x = layers.Concatenate()([x, noise_embedding]) \n",
    "\n",
    "skips = [] #保存DownBlock函数的中间数据，给UpBlock函数调用\n",
    "\n",
    "x = DownBlock(32, block_depth=2)([x, skips]) #该函数共产生2个中间结果，放到skip列表中，然后下采样作为返回值\n",
    "x = DownBlock(64, block_depth=2)([x, skips])\n",
    "x = DownBlock(96, block_depth=2)([x, skips])\n",
    "\n",
    "x = ResidualBlock(128)(x)\n",
    "x = ResidualBlock(128)(x)\n",
    "\n",
    "x = UpBlock(96, block_depth=2)([x, skips])\n",
    "x = UpBlock(64, block_depth=2)([x, skips])\n",
    "x = UpBlock(32, block_depth=2)([x, skips])\n",
    "\n",
    "x = layers.Conv2D(CHANNELS, kernel_size=1, kernel_initializer=\"zeros\")(x) #输出是预测的噪音\n",
    "\n",
    "unet = models.Model([noisy_images, noise_variances], x, name=\"unet\") #输入带有噪音的图像、噪音方差，输出是预测的噪音。仅用于def denoise()调用。\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15745f6-c453-4342-af50-cd4fbf4556f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DiffusionModel(models.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.normalizer = layers.Normalization() #标准化预处理层。“layers.Normalization()的含义.png”\n",
    "        self.network = unet\n",
    "        self.ema_network = models.clone_model(self.network) #克隆模型（但是不会克隆权重）\n",
    "        self.diffusion_schedule = offset_cosine_diffusion_schedule #是否需要加括号？答：不需要，这里相当于属性值，然后调用时加括号。\n",
    "\n",
    "    def compile(self, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.noise_loss_tracker = metrics.Mean(name=\"n_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.noise_loss_tracker]\n",
    "\n",
    "    def denormalize(self, images): \n",
    "        images = self.normalizer.mean + images * self.normalizer.variance**0.5 #variance 方差值\n",
    "        return tf.clip_by_value(images, 0.0, 1.0)\n",
    "\n",
    "    def denoise(self, noisy_images, noise_rates, signal_rates, training):\n",
    "        if training:\n",
    "            network = self.network\n",
    "        else:\n",
    "            network = self.ema_network\n",
    "        pred_noises = network([noisy_images, noise_rates**2], training=training) \n",
    "        #去噪神经网络理解：如同一个神探，看到尸体腐烂的照片，根据死亡时间（用于推算腐烂比例或者程度），就能还原出尸体初始状态。这个神探是如何有这项本领的？答：他是通过研究许多尸体腐烂过程，不断修正自己的认知获得的。\n",
    "        pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n",
    "\n",
    "        return pred_noises, pred_images\n",
    "\n",
    "    def reverse_diffusion(self, initial_noise, diffusion_steps):\n",
    "        num_images = initial_noise.shape[0] #获取生成图像的数目\n",
    "        step_size = 1.0 / diffusion_steps\n",
    "        current_images = initial_noise\n",
    "        for step in range(diffusion_steps): #step=[0,1,2~,18,19]\n",
    "            diffusion_times = tf.ones((num_images, 1, 1, 1)) - step * step_size #diffusion_times腐蚀程度（1~0.05，数值越大腐蚀程度越高）\n",
    "            noise_rates, signal_rates = self.diffusion_schedule(diffusion_times) \n",
    "            pred_noises, pred_images = self.denoise(  #注意，每步pred_noises均不同的\n",
    "                current_images, noise_rates, signal_rates, training=False\n",
    "            )\n",
    "            next_diffusion_times = diffusion_times - step_size\n",
    "            next_noise_rates, next_signal_rates = self.diffusion_schedule(next_diffusion_times)\n",
    "            current_images = (\n",
    "                next_signal_rates * pred_images + next_noise_rates * pred_noises #《生成式深度学习 英文第二版》P226中间公式。\n",
    "            )\n",
    "        return pred_images #为什么不直接采用X0？答：神经网络性能达不到。\n",
    "\n",
    "    def generate(self, num_images, diffusion_steps, initial_noise=None):\n",
    "        if initial_noise is None:\n",
    "            initial_noise = tf.random.normal(\n",
    "                shape=(num_images, IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS)\n",
    "            )\n",
    "        generated_images = self.reverse_diffusion(\n",
    "            initial_noise, diffusion_steps\n",
    "        )\n",
    "        generated_images = self.denormalize(generated_images)\n",
    "        return generated_images\n",
    "\n",
    "    def train_step(self, images):\n",
    "        images = self.normalizer(images, training=True) #“layers.Normalization()的含义.png”。这里将输入图像批次标准化\n",
    "        noises = tf.random.normal(shape=(BATCH_SIZE, IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS))  #标准正态分布中采样噪声\n",
    "\n",
    "        diffusion_times = tf.random.uniform(shape=(BATCH_SIZE, 1, 1, 1), minval=0.0, maxval=1.0) #均匀分布中采样。下限 minval包含在范围内，而上限maxval被排除在外。\n",
    "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times) \n",
    "\n",
    "        noisy_images = signal_rates * images + noise_rates * noises #将输入图像加上噪音\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # train the network to separate noisy images to their components\n",
    "            pred_noises, pred_images = self.denoise(noisy_images, noise_rates, signal_rates, training=True) \n",
    "\n",
    "            noise_loss = self.loss(noises, pred_noises) \n",
    "\n",
    "        gradients = tape.gradient(noise_loss, self.network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        self.noise_loss_tracker.update_state(noise_loss)\n",
    "\n",
    "        for weight, ema_weight in zip(\n",
    "            self.network.weights, self.ema_network.weights\n",
    "        ):\n",
    "            ema_weight.assign(EMA * ema_weight + (1 - EMA) * weight) #“.assign()”是tf变量赋值的方法\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, images):\n",
    "        images = self.normalizer(images, training=False)\n",
    "        noises = tf.random.normal(shape=(BATCH_SIZE, IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS))\n",
    "        diffusion_times = tf.random.uniform(\n",
    "            shape=(BATCH_SIZE, 1, 1, 1), minval=0.0, maxval=1.0\n",
    "        )\n",
    "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
    "        noisy_images = signal_rates * images + noise_rates * noises\n",
    "        pred_noises, pred_images = self.denoise(\n",
    "            noisy_images, noise_rates, signal_rates, training=False\n",
    "        )\n",
    "        noise_loss = self.loss(noises, pred_noises)\n",
    "        self.noise_loss_tracker.update_state(noise_loss)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "'''\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        pass\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe9df93-c04f-47a9-8686-747e1aba1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddm = DiffusionModel()\n",
    "\n",
    "ddm.normalizer.adapt(train) #“layers.Normalization()的含义.png”。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be3d70-53be-492b-af23-2432d73405e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    ddm.built = True\n",
    "    ddm.load_weights(\"./checkpoint/checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f392424-45a9-49cc-8ea0-c1bec9064d74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.Train the model <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da961bb-f8ed-4eb3-ae6d-2af32a3c8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddm.compile(\n",
    "    optimizer=optimizers.experimental.AdamW(  #“AdamW简单易用效果好.mhtml”\n",
    "        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    "    ),\n",
    "    loss=losses.mean_absolute_error, #keras官方函数，计算标签和预测之间的绝对差值的平均值。mse 损失函数，即均方误差（MSE，mean squared error），预测值与目标值之差的平方。平均绝对误差（MAE，mean absolute error），它是预测值与目标值之差的绝对值。\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e012b8-1fe7-40e9-9fb1-3fb2c3cbcb23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run training and plot generated images periodically\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoint/checkpoint{epoch:02d}.ckpt\", \n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "\n",
    "class ImageGenerator(callbacks.Callback):\n",
    "    def __init__(self, num_img):\n",
    "        self.num_img = num_img\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        generated_images = self.model.generate(\n",
    "            num_images=self.num_img,\n",
    "            diffusion_steps=PLOT_DIFFUSION_STEPS,\n",
    "        ).numpy()\n",
    "        display(\n",
    "            generated_images,\n",
    "            n=self.num_img,  #自增\n",
    "            size=(80, 2),   #自增，这种比例清晰度高   \n",
    "            save_to=\"./output/generated_img_%03d.png\" % (epoch),\n",
    "        )\n",
    "\n",
    "\n",
    "image_generator_callback = ImageGenerator(num_img=10)\n",
    "\n",
    "history=ddm.fit(\n",
    "    train,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        model_checkpoint_callback,\n",
    "        tensorboard_callback,\n",
    "        image_generator_callback,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082b1c6-0872-4067-ac7d-05f6375d7d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history.history.txt', 'w') as file_object:file_object.write(str(history.history)+'\\n')  #损失写入文件\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss = history_dict['n_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'b', label='loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180fb0a1-ed16-47c2-b326-ad66071cd6e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Inference <a name=\"inference\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84db7dcc-313d-41b6-9357-c403ea97add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some novel images of flowers\n",
    "generated_images = ddm.generate(num_images=10, diffusion_steps=20).numpy()\n",
    "display(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d6859-652e-421a-974b-75ce3c919244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View improvement over greater number of diffusion steps\n",
    "for diffusion_steps in list(np.arange(1, 6, 1)) + [20] + [100]:\n",
    "    tf.random.set_seed(42)\n",
    "    generated_images = ddm.generate(\n",
    "        num_images=10,\n",
    "        diffusion_steps=diffusion_steps,\n",
    "    ).numpy()\n",
    "    display(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2254193-c1ab-43fa-97f9-976723898abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Interpolation between two points in the latent space\n",
    "tf.random.set_seed(100)\n",
    "\n",
    "\n",
    "def spherical_interpolation(a, b, t):\n",
    "    return np.sin(t * math.pi / 2) * a + np.cos(t * math.pi / 2) * b\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    a = tf.random.normal(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS))\n",
    "    b = tf.random.normal(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS))\n",
    "    initial_noise = np.array(\n",
    "        [spherical_interpolation(a, b, t) for t in np.arange(0, 1.1, 0.1)]\n",
    "    )\n",
    "    generated_images = ddm.generate(\n",
    "        num_images=2, diffusion_steps=20, initial_noise=initial_noise\n",
    "    ).numpy()\n",
    "    display(generated_images, n=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704bce2f-c567-4382-a959-f5dfe7b538f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "endTime=time.time()\n",
    "print('How many minutes:',(endTime-startTime)/60) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
