{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b076bd1a-b236-4fbc-953d-8295b25122ae",
   "metadata": {},
   "source": [
    "# ğŸ”¥ Diffusion Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235cbd1-f136-411c-88d9-f69f270c0b96",
   "metadata": {},
   "source": [
    "In this notebook, we'll walk through the steps required to train your own diffusion model on the Oxford flowers dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bacc8be-c1d2-4108-aa7c-7453dbc777a6",
   "metadata": {},
   "source": [
    "The code is adapted from the excellent ['Denoising Diffusion Implicit Models' tutorial](https://keras.io/examples/generative/ddim/) created by AndrÃ¡s BÃ©res available on the Keras website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84acc7be-6764-4668-b2bb-178f63deeed3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseaborn-v0_8-colorblind\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     layers,\n\u001b[0;32m     13\u001b[0m     models,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     activations,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnotebooks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display, sample_batch\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\__init__.py:42\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:96\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:419\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompress\u001b[39m(element):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwrapt\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py:36\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"## Functions for working with arbitrarily nested sequences of elements.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03mNOTE(mrry): This fork of the `tensorflow.python.util.nest` module\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m   arrays.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m _sparse_tensor\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_util\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m type_spec\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_sparse_ops\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m internal\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\ops\\gen_sparse_ops.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m op_def_registry \u001b[38;5;28;01mas\u001b[39;00m _op_def_registry\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops \u001b[38;5;28;01mas\u001b[39;00m _ops\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m op_def_library \u001b[38;5;28;01mas\u001b[39;00m _op_def_library\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated_endpoints\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch \u001b[38;5;28;01mas\u001b[39;00m _dispatch\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text_format\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flags\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_pb2\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf2.10GPU_py3.10.13\\lib\\site-packages\\tensorflow\\core\\config\\flags.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# pylint: disable=invalid-import-order, g-bad-import-order, unused-import\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flags_pybind\n\u001b[0;32m     22\u001b[0m FLAGS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfig\u001b[39m():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-colorblind\")\n",
    "\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import (\n",
    "    layers,\n",
    "    models,\n",
    "    optimizers,\n",
    "    utils,\n",
    "    callbacks,\n",
    "    metrics,\n",
    "    losses,\n",
    "    activations,\n",
    ")\n",
    "\n",
    "from notebooks.utils import display, sample_batch\n",
    "\n",
    "import time\n",
    "startTime=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5",
   "metadata": {},
   "source": [
    "## 0. Parameters <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ee6ce-129f-4833-b0c5-fa567381c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#è°ƒæ•´å‚æ•°\n",
    "BATCH_SIZE = 64 #æŸ¥çœ‹æ˜¾å­˜å ç”¨æ¯”ä¾‹â€œnvidia-smiâ€ã€‚\n",
    "DATASET_REPETITIONS = 5 #æ•°æ®é›†çš„é‡å¤æ¬¡æ•°ã€‚\n",
    "LOAD_MODEL = False\n",
    "\n",
    "NOISE_EMBEDDING_SIZE = 32 #æ­£å¼¦åµŒå…¥å±‚å°†ä¸€ä¸ªæ ‡é‡æ•°å€¼ (å™ªå£°æ–¹å·®) è½¬æ¢åˆ°ä¸€ä¸ªå‘é‡ï¼Œ32å³å‘é‡ç»´æ•°\n",
    "PLOT_DIFFUSION_STEPS = 20 #ç”Ÿæˆå›¾åƒæ—¶ï¼Œå»é™¤å™ªéŸ³çš„æ­¥éª¤æ•°ç›®\n",
    "\n",
    "EMA = 0.999 #æŒ‡æ•°ç§»åŠ¨å¹³å‡å‚æ•°\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "EPOCHS = 150 # 4m/è½®/(48, 192)\n",
    "\n",
    "#å›ºå®šå‚æ•°\n",
    "train_dir=\".\\\\png 192x48_GRAY\\\\\" #æ–‡ä»¶åå­—ç¬¦æ•°ç›®ä¸èƒ½è¿‡å¤šï¼Œå¦åˆ™å‡ºé”™ï¼Œæ•…åœ¨æ—‹è½¬ã€ç¼©æ”¾ã€å¹³ç§»å˜æ¢æ—¶å‡å°‘æ–‡ä»¶åå­—ç¬¦ã€‚\n",
    "IMAGE_SIZE =  (48, 192) #å†å°æ¸…æ™°åº¦å°±ä¸æ»¡è¶³äº†\n",
    "CHANNELS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f5e63-e36a-4dc8-9f03-cb29c1fa5290",
   "metadata": {},
   "source": [
    "## 1. Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089c317-2d66-4631-81f8-1a8230635845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = utils.image_dataset_from_directory(\n",
    "    train_dir,  \n",
    "    labels=None,\n",
    "    color_mode=\"grayscale\", #é»˜è®¤RGBä¸‰é€šé“\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=None,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    interpolation=\"bilinear\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20697102-8c8d-4582-88d4-f8e2af84e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "def preprocess(img):\n",
    "    img = tf.cast(img, \"float32\") / 255.0 #tf.cast()å‡½æ•°ï¼šæ•°æ®ç±»å‹è½¬æ¢.ç”±0~255æ”¾ç¼©åˆ°0~1\n",
    "    return img\n",
    "\n",
    "\n",
    "train = train_data.map(lambda x: preprocess(x))\n",
    "train = train.repeat(DATASET_REPETITIONS) #repeat(count) ç”¨äºå°†æ•°æ®é‡å¤countæ¬¡ï¼Œç›¸å½“äºæˆ‘ä»¬è®­ç»ƒæ—¶çš„epoch\n",
    "train = train.batch(BATCH_SIZE, drop_remainder=True) #batch(batch_size)ç”¨äºå°†æ•°æ®åˆ’åˆ†ä¸ºå¤šä¸ªbatchã€‚     drop_remainderï¼šTrueè¡¨ç¤ºå‰©ä¸‹çš„æ•°æ®ä¸è¶³batch_sizeä¸ª ä»æ‰ã€‚é»˜è®¤å€¼ä¸ºFalse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1a420-699e-4869-8d10-3c049dbad030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some items of clothing from the training set\n",
    "train_sample = sample_batch(train)\n",
    "print(train_sample.shape) \n",
    "np.savetxt('train_sample[0].txt', train_sample[0][:,:,0])  #åƒç´ å€¼0~1\n",
    "display(train_sample, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53945d9-b7c5-49d0-a356-bcf1d1e1798b",
   "metadata": {},
   "source": [
    "### 1.1 Diffusion schedules <a name=\"diffusion_schedules\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330083c0-642e-4745-b160-1938493152da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#è¿™ä¸ªæ–¹æ¡ˆæœ€å¤æ‚\n",
    "def linear_diffusion_schedule(diffusion_times): #çº¿æ€§æ‰©æ•£è®¡åˆ’ã€‚0~1å‡åŒ€åˆ†å¸ƒã€‚\n",
    "    min_rate = 0.0001 #ä¸€å¼€å§‹çš„betaå€¼ï¼Œå³ä¸€å¼€å§‹æ·»åŠ 1%çš„å™ªéŸ³\n",
    "    max_rate = 0.02 #æœ€åä¸€æ­¥çš„betaå€¼ï¼Œå¯è§æ·»åŠ å™ªéŸ³çš„æ¯”ä¾‹è¶Šæ¥è¶Šå¤§\n",
    "    betas = min_rate + diffusion_times * (max_rate - min_rate) #min_rate~max_rateå‡åŒ€åˆ†å¸ƒã€‚\n",
    "    alphas = 1 - betas #0.9999~0.98002å‡åŒ€åˆ†å¸ƒ\n",
    "    alpha_bars = tf.math.cumprod(alphas) #cumprod()ç”¨äºè®¡ç®—è¾“å…¥å¼ é‡çš„ç´¯ç§¯ä¹˜ç§¯\n",
    "    signal_rates = tf.sqrt(alpha_bars) #è¿”å›å¼ é‡æ¯ä¸ªå…ƒç´ çš„å¹³æ–¹æ ¹ã€‚\n",
    "    noise_rates = tf.sqrt(1 - alpha_bars) #å«æœ‰å™ªéŸ³çš„æ¯”ä¾‹ï¼Œç”±0å‘1æ¼”å˜.\n",
    "    return noise_rates, signal_rates #â€œçº¿æ€§æ‰©æ•£ä»£ç è§£é‡Š.pngâ€\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08bb63-148f-4813-96c6-adec54d8956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#è¿™ä¸ªæ–¹æ¡ˆæœ€ç®€å•ï¼Œdiffusion_timesçº¦ç­‰äºnoise_rates\n",
    "def cosine_diffusion_schedule(diffusion_times): \n",
    "    signal_rates = tf.cos(diffusion_times * math.pi / 2)\n",
    "    noise_rates = tf.sin(diffusion_times * math.pi / 2)\n",
    "    return noise_rates, signal_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e1557-4ea5-4cd8-8f41-66a99ee3898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#æœ€ç»ˆé‡‡ç”¨çš„æ–¹æ¡ˆï¼Œdiffusion_timesç›¸å½“äºnoise_rates[ä½†æ˜¯æœ‰ç‚¹åå·®]\n",
    "# æˆ‘ä»¬å°†ä½¿ç”¨çš„offset cosineæ‰©æ•£è®¡åˆ’ï¼Œå…¶è°ƒæ•´è®¡åˆ’æ¥ç¡®ä¿åŠ å™ªstepsåœ¨åŠ å™ªçš„å¼€å§‹é˜¶æ®µä¸è‡³äºè¿‡å°ã€‚\n",
    "def offset_cosine_diffusion_schedule(diffusion_times):\n",
    "    min_signal_rate = 0.02\n",
    "    max_signal_rate = 0.95\n",
    "    start_angle = tf.acos(max_signal_rate) #18.2åº¦\n",
    "    end_angle = tf.acos(min_signal_rate) #88.9åº¦\n",
    "\n",
    "    diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n",
    "\n",
    "    signal_rates = tf.cos(diffusion_angles) #åœ¨0.95~0.02ä¹‹é—´\n",
    "    noise_rates = tf.sin(diffusion_angles) #0.312~0.9998ã€‚diffusion_timesï¼ˆ0~1ï¼‰ç›¸å½“äºnoise_rates[ä½†æ˜¯æœ‰ç‚¹åå·®]\n",
    "\n",
    "    return noise_rates, signal_rates\n",
    "\n",
    "diffusion_times=tf.convert_to_tensor([(1-x*1 / 20) for x in range(20)])\n",
    "print(diffusion_times)\n",
    "print(offset_cosine_diffusion_schedule(diffusion_times))\n",
    "print(offset_cosine_diffusion_schedule(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5f3c3-4797-4b58-b559-45589f59aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1000\n",
    "diffusion_times = tf.convert_to_tensor([x / T for x in range(T)]) #0~1å‡åŒ€åˆ†å¸ƒã€‚\n",
    "\n",
    "linear_noise_rates, linear_signal_rates = linear_diffusion_schedule(    diffusion_times)\n",
    "cosine_noise_rates, cosine_signal_rates = cosine_diffusion_schedule(    diffusion_times)\n",
    "(    offset_cosine_noise_rates,    offset_cosine_signal_rates,) = offset_cosine_diffusion_schedule(diffusion_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b7b5a-c79c-4728-8778-10656541dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    diffusion_times, linear_signal_rates**2, linewidth=1.5, label=\"linear\"\n",
    ")\n",
    "plt.plot(\n",
    "    diffusion_times, cosine_signal_rates**2, linewidth=1.5, label=\"cosine\"\n",
    ")\n",
    "plt.plot(\n",
    "    diffusion_times,    offset_cosine_signal_rates**2,    linewidth=1.5,    label=\"offset_cosine\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"t/T\", fontsize=12)\n",
    "plt.ylabel(r\"$\\bar{\\alpha_t}$ (signal)\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eac1df-3a74-4432-9d4d-0ccfbb5dc24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    diffusion_times, linear_noise_rates**2, linewidth=1.5, label=\"linear\"\n",
    ")\n",
    "plt.plot(\n",
    "    diffusion_times, cosine_noise_rates**2, linewidth=1.5, label=\"cosine\"\n",
    ")\n",
    "plt.plot(\n",
    "    diffusion_times,\n",
    "    offset_cosine_noise_rates**2,\n",
    "    linewidth=1.5,\n",
    "    label=\"offset_cosine\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"t/T\", fontsize=12)\n",
    "plt.ylabel(r\"$1-\\bar{\\alpha_t}$ (noise)\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598d401-867d-450c-a3ba-6823bf309456",
   "metadata": {},
   "source": [
    "## 2. Build the model <a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b305c3a-75c5-4b02-9130-79b661fc63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_embedding(x):  #æ­£å¼¦åµŒå…¥å±‚ï¼Œå°†ä¸€ä¸ªæ ‡é‡æ•°å€¼ (å™ªå£°æ–¹å·®) è½¬æ¢åˆ°ä¸€ä¸ªå‘é‡ï¼ˆå¯¹åº”å›¾åƒé€šé“ï¼‰\n",
    "    frequencies = tf.exp(   #æœ€ç»ˆå¾—åˆ°æŒ‡æ•°å€¼\n",
    "        tf.linspace(          #å‡åŒ€åˆ†å¸ƒï¼Œè¿”å›ä¸ºé¢‘ç‡çš„æœ€å¤§æ”¾ç¼©å› å­\n",
    "            tf.math.log(1.0), #ä»0åˆ°ln(1000)\n",
    "            tf.math.log(1000.0),\n",
    "            NOISE_EMBEDDING_SIZE // 2,  #ç”Ÿæˆçš„ä¸ªæ•°\n",
    "        )\n",
    "    )\n",
    "    angular_speeds = 2.0 * math.pi * frequencies\n",
    "    embeddings = tf.concat(\n",
    "        [tf.sin(angular_speeds * x), tf.cos(angular_speeds * x)], axis=3\n",
    "    )\n",
    "    return embeddings #è¿™ä¸ªå‡½æ•°è¾“å…¥æ˜¯æ–¹å·®æ ‡é‡ï¼Œè¾“å‡ºç»“æœshapeæ˜¯(1x1x32)ï¼Œå€¼ä¸º-1~1ï¼ˆsinã€coså‡½æ•°å€¼åŸŸï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711f6fb-6b43-4e79-9450-faef9f2afdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = []\n",
    "for y in np.arange(0, 1, 0.01): #yä¸ºå™ªéŸ³æ–¹å·®\n",
    "    embedding_list.append(sinusoidal_embedding(np.array([[[[y]]]]))[0][0][0])\n",
    "embedding_array = np.array(np.transpose(embedding_list))  #np.transposeï¼ˆï¼‰æ•°ç»„è½¬ç½®\n",
    "fig, ax = plt.subplots() #figä»£è¡¨ç»˜å›¾çª—å£(Figure)ï¼›axä»£è¡¨è¿™ä¸ªç»˜å›¾çª—å£ä¸Šçš„åæ ‡ç³»(axis)ï¼Œä¸€èˆ¬ä¼šç»§ç»­å¯¹axè¿›è¡Œæ“ä½œã€‚\n",
    "ax.set_xticks(\n",
    "    np.arange(0, 100, 10), labels=np.round(np.arange(0.0, 1.0, 0.1), 1)\n",
    ")\n",
    "ax.set_ylabel(\"embedding dimension\", fontsize=8) #è¿™é‡Œæœ‰32ä¸ªå€¼\n",
    "ax.set_xlabel(\"noise variance\", fontsize=8)\n",
    "plt.pcolor(embedding_array, cmap=\"coolwarm\") #plt.pcolor()æ˜¯matplotlibåº“ä¸­çš„ä¸€ç§2Då›¾åƒç»˜åˆ¶å‡½æ•°ï¼Œå®ƒå¯ä»¥æ ¹æ®æ•°æ®å€¼çš„å¤§å°è‡ªåŠ¨å¡«å……ä¸åŒé¢œè‰²ï¼Œä»è€Œä¸ºæˆ‘ä»¬å±•ç¤ºå‡ºæ•°æ®çš„åˆ†å¸ƒæƒ…å†µã€‚\n",
    "plt.colorbar(orientation=\"horizontal\", label=\"embedding value\") #æ·»åŠ é¢œè‰²æ¡\n",
    "#ax.imshow(embedding_array, interpolation=\"nearest\", origin=\"lower\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac9c2c-c5bc-4533-b78f-0c878a33893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualBlock(width): #widthé€šé“æ•°\n",
    "    def apply(x): #è¿™é‡Œä¸¤ä¸ªdefå®šä¹‰å‡½æ•°ï¼Œè¿™æ˜¯â€œå‡½æ•°åµŒå¥—.pngâ€\n",
    "        input_width = x.shape[3] #å›¾åƒxçš„é€šé“æ•°\n",
    "        if input_width == width: #æ£€æŸ¥è¾“å…¥çš„é€šé“æ•°æ˜¯å¦åŒ¹é…ï¼Œå¦‚ä¸æ˜¯åˆ™åœ¨è·³è·ƒè¿æ¥ä¸Šå¼•å…¥ä¸€ä¸ªé¢å¤–çš„Conv2Då±‚\n",
    "            residual = x\n",
    "        else:\n",
    "            residual = layers.Conv2D(width, kernel_size=1)(x)\n",
    "        x = layers.BatchNormalization(center=False, scale=False)(x) #kerasæ‰¹æ ‡å‡†åŒ–\n",
    "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\", activation=activations.swish)(x)\n",
    "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
    "        x = layers.Add()([x, residual]) #layers.add()ç›¸åº”å…ƒç´ æ•°å€¼ç›¸åŠ ï¼ŒH,W,Cä¸æ”¹å˜ï¼›tf.keras.layers.concatenateï¼ˆï¼‰æ‹¼æ¥ï¼ŒH ã€ W ä¸æ”¹å˜ ï¼Œ ä½†æ˜¯é€šé“æ•°å¢åŠ \n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "def DownBlock(width, block_depth): #widthé€šé“æ•°\n",
    "    def apply(x): \n",
    "        x, skips = x \n",
    "        for _ in range(block_depth):\n",
    "            x = ResidualBlock(width)(x) #è¿™é‡Œä¸¤ä¸ªè¾“å…¥è§â€œå‡½æ•°åµŒå¥—.pngâ€\n",
    "            skips.append(x)\n",
    "        x = layers.AveragePooling2D(pool_size=2)(x) #å¹³å‡æ± åŒ–å±‚ï¼Œpool_size æ± åŒ–çª—å£å¤§å°ï¼Œstrides: æ± åŒ–æ­¥é•¿ï¼Œé»˜è®¤å€¼ç­‰äº pool_size\n",
    "        return x\n",
    "\n",
    "    return apply \n",
    "\n",
    "\n",
    "def UpBlock(width, block_depth):\n",
    "    def apply(x):\n",
    "        x, skips = x \n",
    "        x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x)\n",
    "        for _ in range(block_depth):\n",
    "            x = layers.Concatenate()([x, skips.pop()]) #åˆ—è¡¨pop()æ–¹æ³•ï¼šåˆ é™¤å¹¶è¿”å›åˆ—è¡¨ä¸­çš„æœ€åä¸€ä¸ªå…ƒç´ ã€‚\n",
    "            x = ResidualBlock(width)(x)\n",
    "        return x \n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8455e5d-2cc7-4d72-94e1-412a0f5e69b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the U-Net\n",
    "\n",
    "noisy_images = layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS)) #è¾“å…¥å¸¦æœ‰å™ªéŸ³çš„å›¾åƒ\n",
    "x = layers.Conv2D(32, kernel_size=1)(noisy_images)\n",
    "\n",
    "noise_variances = layers.Input(shape=(1, 1, 1)) #è¾“å…¥å™ªéŸ³æ–¹å·®ã€‚\n",
    "noise_embedding = layers.Lambda(sinusoidal_embedding)(noise_variances) \n",
    "noise_embedding = layers.UpSampling2D(size=IMAGE_SIZE, interpolation=\"nearest\")(noise_embedding) \n",
    "\n",
    "x = layers.Concatenate()([x, noise_embedding]) \n",
    "\n",
    "skips = [] #ä¿å­˜DownBlockå‡½æ•°çš„ä¸­é—´æ•°æ®ï¼Œç»™UpBlockå‡½æ•°è°ƒç”¨\n",
    "\n",
    "x = DownBlock(32, block_depth=2)([x, skips]) #è¯¥å‡½æ•°å…±äº§ç”Ÿ2ä¸ªä¸­é—´ç»“æœï¼Œæ”¾åˆ°skipåˆ—è¡¨ä¸­ï¼Œç„¶åä¸‹é‡‡æ ·ä½œä¸ºè¿”å›å€¼\n",
    "x = DownBlock(64, block_depth=2)([x, skips])\n",
    "x = DownBlock(96, block_depth=2)([x, skips])\n",
    "\n",
    "x = ResidualBlock(128)(x)\n",
    "x = ResidualBlock(128)(x)\n",
    "\n",
    "x = UpBlock(96, block_depth=2)([x, skips])\n",
    "x = UpBlock(64, block_depth=2)([x, skips])\n",
    "x = UpBlock(32, block_depth=2)([x, skips])\n",
    "\n",
    "x = layers.Conv2D(CHANNELS, kernel_size=1, kernel_initializer=\"zeros\")(x) #è¾“å‡ºæ˜¯é¢„æµ‹çš„å™ªéŸ³\n",
    "\n",
    "unet = models.Model([noisy_images, noise_variances], x, name=\"unet\") #è¾“å…¥å¸¦æœ‰å™ªéŸ³çš„å›¾åƒã€å™ªéŸ³æ–¹å·®ï¼Œè¾“å‡ºæ˜¯é¢„æµ‹çš„å™ªéŸ³ã€‚ä»…ç”¨äºdef denoise()è°ƒç”¨ã€‚\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15745f6-c453-4342-af50-cd4fbf4556f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DiffusionModel(models.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.normalizer = layers.Normalization() #æ ‡å‡†åŒ–é¢„å¤„ç†å±‚ã€‚â€œlayers.Normalization()çš„å«ä¹‰.pngâ€\n",
    "        self.network = unet\n",
    "        self.ema_network = models.clone_model(self.network) #å…‹éš†æ¨¡å‹ï¼ˆä½†æ˜¯ä¸ä¼šå…‹éš†æƒé‡ï¼‰\n",
    "        self.diffusion_schedule = offset_cosine_diffusion_schedule #æ˜¯å¦éœ€è¦åŠ æ‹¬å·ï¼Ÿç­”ï¼šä¸éœ€è¦ï¼Œè¿™é‡Œç›¸å½“äºå±æ€§å€¼ï¼Œç„¶åè°ƒç”¨æ—¶åŠ æ‹¬å·ã€‚\n",
    "\n",
    "    def compile(self, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.noise_loss_tracker = metrics.Mean(name=\"n_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.noise_loss_tracker]\n",
    "\n",
    "    def denormalize(self, images): \n",
    "        images = self.normalizer.mean + images * self.normalizer.variance**0.5 #variance æ–¹å·®å€¼\n",
    "        return tf.clip_by_value(images, 0.0, 1.0)\n",
    "\n",
    "    def denoise(self, noisy_images, noise_rates, signal_rates, training):\n",
    "        if training:\n",
    "            network = self.network\n",
    "        else:\n",
    "            network = self.ema_network\n",
    "        pred_noises = network([noisy_images, noise_rates**2], training=training) \n",
    "        #å»å™ªç¥ç»ç½‘ç»œç†è§£ï¼šå¦‚åŒä¸€ä¸ªç¥æ¢ï¼Œçœ‹åˆ°å°¸ä½“è…çƒ‚çš„ç…§ç‰‡ï¼Œæ ¹æ®æ­»äº¡æ—¶é—´ï¼ˆç”¨äºæ¨ç®—è…çƒ‚æ¯”ä¾‹æˆ–è€…ç¨‹åº¦ï¼‰ï¼Œå°±èƒ½è¿˜åŸå‡ºå°¸ä½“åˆå§‹çŠ¶æ€ã€‚è¿™ä¸ªç¥æ¢æ˜¯å¦‚ä½•æœ‰è¿™é¡¹æœ¬é¢†çš„ï¼Ÿç­”ï¼šä»–æ˜¯é€šè¿‡ç ”ç©¶è®¸å¤šå°¸ä½“è…çƒ‚è¿‡ç¨‹ï¼Œä¸æ–­ä¿®æ­£è‡ªå·±çš„è®¤çŸ¥è·å¾—çš„ã€‚\n",
    "        pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n",
    "\n",
    "        return pred_noises, pred_images\n",
    "\n",
    "    def reverse_diffusion(self, initial_noise, diffusion_steps):\n",
    "        num_images = initial_noise.shape[0] #è·å–ç”Ÿæˆå›¾åƒçš„æ•°ç›®\n",
    "        step_size = 1.0 / diffusion_steps\n",
    "        current_images = initial_noise\n",
    "        for step in range(diffusion_steps): #step=[0,1,2~,18,19]\n",
    "            diffusion_times = tf.ones((num_images, 1, 1, 1)) - step * step_size #diffusion_timesè…èš€ç¨‹åº¦ï¼ˆ1~0.05ï¼Œæ•°å€¼è¶Šå¤§è…èš€ç¨‹åº¦è¶Šé«˜ï¼‰\n",
    "            noise_rates, signal_rates = self.diffusion_schedule(diffusion_times) \n",
    "            pred_noises, pred_images = self.denoise(  #æ³¨æ„ï¼Œæ¯æ­¥pred_noiseså‡ä¸åŒçš„\n",
    "                current_images, noise_rates, signal_rates, training=False\n",
    "            )\n",
    "            next_diffusion_times = diffusion_times - step_size\n",
    "            next_noise_rates, next_signal_rates = self.diffusion_schedule(next_diffusion_times)\n",
    "            current_images = (\n",
    "                next_signal_rates * pred_images + next_noise_rates * pred_noises #ã€Šç”Ÿæˆå¼æ·±åº¦å­¦ä¹  è‹±æ–‡ç¬¬äºŒç‰ˆã€‹P226ä¸­é—´å…¬å¼ã€‚\n",
    "            )\n",
    "        return pred_images #ä¸ºä»€ä¹ˆä¸ç›´æ¥é‡‡ç”¨X0ï¼Ÿç­”ï¼šç¥ç»ç½‘ç»œæ€§èƒ½è¾¾ä¸åˆ°ã€‚\n",
    "\n",
    "    def generate(self, num_images, diffusion_steps, initial_noise=None):\n",
    "        if initial_noise is None:\n",
    "            initial_noise = tf.random.normal(\n",
    "                shape=(num_images, IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS)\n",
    "            )\n",
    "        generated_images = self.reverse_diffusion(\n",
    "            initial_noise, diffusion_steps\n",
    "        )\n",
    "        generated_images = self.denormalize(generated_images)\n",
    "        return generated_images\n",
    "\n",
    "    def train_step(self, images):\n",
    "        images = self.normalizer(images, training=True) #â€œlayers.Normalization()çš„å«ä¹‰.pngâ€ã€‚è¿™é‡Œå°†è¾“å…¥å›¾åƒæ‰¹æ¬¡æ ‡å‡†åŒ–\n",
    "        noises = tf.random.normal(shape=(BATCH_SIZE, IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS))  #æ ‡å‡†æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·å™ªå£°\n",
    "\n",
    "        diffusion_times = tf.random.uniform(shape=(BATCH_SIZE, 1, 1, 1), minval=0.0, maxval=1.0) #å‡åŒ€åˆ†å¸ƒä¸­é‡‡æ ·ã€‚ä¸‹é™ minvalåŒ…å«åœ¨èŒƒå›´å†…ï¼Œè€Œä¸Šé™maxvalè¢«æ’é™¤åœ¨å¤–ã€‚\n",
    "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times) \n",
    "\n",
    "        noisy_images = signal_rates * images + noise_rates * noises #å°†è¾“å…¥å›¾åƒåŠ ä¸Šå™ªéŸ³\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # train the network to separate noisy images to their components\n",
    "            pred_noises, pred_images = self.denoise(noisy_images, noise_rates, signal_rates, training=True) \n",
    "\n",
    "            noise_loss = self.loss(noises, pred_noises) \n",
    "\n",
    "        gradients = tape.gradient(noise_loss, self.network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        self.noise_loss_tracker.update_state(noise_loss)\n",
    "\n",
    "        for weight, ema_weight in zip(\n",
    "            self.network.weights, self.ema_network.weights\n",
    "        ):\n",
    "            ema_weight.assign(EMA * ema_weight + (1 - EMA) * weight) #â€œ.assign()â€æ˜¯tfå˜é‡èµ‹å€¼çš„æ–¹æ³•\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, images):\n",
    "        images = self.normalizer(images, training=False)\n",
    "        noises = tf.random.normal(shape=(BATCH_SIZE, IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS))\n",
    "        diffusion_times = tf.random.uniform(\n",
    "            shape=(BATCH_SIZE, 1, 1, 1), minval=0.0, maxval=1.0\n",
    "        )\n",
    "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
    "        noisy_images = signal_rates * images + noise_rates * noises\n",
    "        pred_noises, pred_images = self.denoise(\n",
    "            noisy_images, noise_rates, signal_rates, training=False\n",
    "        )\n",
    "        noise_loss = self.loss(noises, pred_noises)\n",
    "        self.noise_loss_tracker.update_state(noise_loss)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "'''\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        pass\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe9df93-c04f-47a9-8686-747e1aba1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddm = DiffusionModel()\n",
    "\n",
    "ddm.normalizer.adapt(train) #â€œlayers.Normalization()çš„å«ä¹‰.pngâ€ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be3d70-53be-492b-af23-2432d73405e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    ddm.built = True\n",
    "    ddm.load_weights(\"./checkpoint/checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f392424-45a9-49cc-8ea0-c1bec9064d74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.Train the model <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da961bb-f8ed-4eb3-ae6d-2af32a3c8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddm.compile(\n",
    "    optimizer=optimizers.experimental.AdamW(  #â€œAdamWç®€å•æ˜“ç”¨æ•ˆæœå¥½.mhtmlâ€\n",
    "        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    "    ),\n",
    "    loss=losses.mean_absolute_error, #keraså®˜æ–¹å‡½æ•°ï¼Œè®¡ç®—æ ‡ç­¾å’Œé¢„æµ‹ä¹‹é—´çš„ç»å¯¹å·®å€¼çš„å¹³å‡å€¼ã€‚mse æŸå¤±å‡½æ•°ï¼Œå³å‡æ–¹è¯¯å·®ï¼ˆMSEï¼Œmean squared errorï¼‰ï¼Œé¢„æµ‹å€¼ä¸ç›®æ ‡å€¼ä¹‹å·®çš„å¹³æ–¹ã€‚å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼Œmean absolute errorï¼‰ï¼Œå®ƒæ˜¯é¢„æµ‹å€¼ä¸ç›®æ ‡å€¼ä¹‹å·®çš„ç»å¯¹å€¼ã€‚\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e012b8-1fe7-40e9-9fb1-3fb2c3cbcb23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run training and plot generated images periodically\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoint/checkpoint{epoch:02d}.ckpt\", \n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "\n",
    "class ImageGenerator(callbacks.Callback):\n",
    "    def __init__(self, num_img):\n",
    "        self.num_img = num_img\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        generated_images = self.model.generate(\n",
    "            num_images=self.num_img,\n",
    "            diffusion_steps=PLOT_DIFFUSION_STEPS,\n",
    "        ).numpy()\n",
    "        display(\n",
    "            generated_images,\n",
    "            n=self.num_img,  #è‡ªå¢\n",
    "            size=(80, 2),   #è‡ªå¢ï¼Œè¿™ç§æ¯”ä¾‹æ¸…æ™°åº¦é«˜   \n",
    "            save_to=\"./output/generated_img_%03d.png\" % (epoch),\n",
    "        )\n",
    "\n",
    "\n",
    "image_generator_callback = ImageGenerator(num_img=10)\n",
    "\n",
    "history=ddm.fit(\n",
    "    train,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        model_checkpoint_callback,\n",
    "        tensorboard_callback,\n",
    "        image_generator_callback,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082b1c6-0872-4067-ac7d-05f6375d7d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history.history.txt', 'w') as file_object:file_object.write(str(history.history)+'\\n')  #æŸå¤±å†™å…¥æ–‡ä»¶\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss = history_dict['n_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'b', label='loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180fb0a1-ed16-47c2-b326-ad66071cd6e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Inference <a name=\"inference\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84db7dcc-313d-41b6-9357-c403ea97add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some novel images of flowers\n",
    "generated_images = ddm.generate(num_images=10, diffusion_steps=20).numpy()\n",
    "display(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d6859-652e-421a-974b-75ce3c919244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View improvement over greater number of diffusion steps\n",
    "for diffusion_steps in list(np.arange(1, 6, 1)) + [20] + [100]:\n",
    "    tf.random.set_seed(42)\n",
    "    generated_images = ddm.generate(\n",
    "        num_images=10,\n",
    "        diffusion_steps=diffusion_steps,\n",
    "    ).numpy()\n",
    "    display(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2254193-c1ab-43fa-97f9-976723898abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Interpolation between two points in the latent space\n",
    "tf.random.set_seed(100)\n",
    "\n",
    "\n",
    "def spherical_interpolation(a, b, t):\n",
    "    return np.sin(t * math.pi / 2) * a + np.cos(t * math.pi / 2) * b\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    a = tf.random.normal(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS))\n",
    "    b = tf.random.normal(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS))\n",
    "    initial_noise = np.array(\n",
    "        [spherical_interpolation(a, b, t) for t in np.arange(0, 1.1, 0.1)]\n",
    "    )\n",
    "    generated_images = ddm.generate(\n",
    "        num_images=2, diffusion_steps=20, initial_noise=initial_noise\n",
    "    ).numpy()\n",
    "    display(generated_images, n=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704bce2f-c567-4382-a959-f5dfe7b538f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "endTime=time.time()\n",
    "print('How many minutes:',(endTime-startTime)/60) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
